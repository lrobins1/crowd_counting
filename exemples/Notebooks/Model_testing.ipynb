{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_testing.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Setup"],"metadata":{"id":"Zf_jvQT_esDj"}},{"cell_type":"markdown","source":["##Imports"],"metadata":{"id":"_ide-dmFknsS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch')\n","\n","import h5py\n","import scipy.io as io\n","import PIL.Image as Image\n","import numpy as np\n","import os\n","import json\n","import glob\n","from matplotlib import pyplot as plt\n","from scipy.ndimage.filters import gaussian_filter \n","import scipy\n","from scipy import spatial\n","import json\n","from matplotlib import cm as CM\n","from image import *\n","from model import CSRNet\n","import torch\n","import torchvision.transforms.functional as F\n","from matplotlib import cm as CM\n","import random\n","from torchvision import datasets, transforms\n","transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],          std=[0.229, 0.224, 0.225]),\n","                   ])\n","                          \n","%matplotlib inline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWjejkXReusk","executionInfo":{"status":"ok","timestamp":1645179069650,"user_tz":-60,"elapsed":38290,"user":{"displayName":"Louis Robins","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhueyELRByt_6yHYZLZUBDypbjIY4OwCQ6n_lCg=s64","userId":"13275034401234860759"}},"outputId":"7f53d9f9-58b0-4202-e2e2-73b56329cd9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["##Paths"],"metadata":{"id":"8Db15fVgg0L6"}},{"cell_type":"code","source":["root = '/content/gdrive/MyDrive/TFE_crowd_counting'\n","dataset_path = os.path.join(root,'Dataset')\n","images_path = os.path.join(dataset_path,'images')\n","path_sets = [images_path]  #All images at the same place\n","scripts_path = os.path.join(root,'CSRNet-pytorch')\n","\n","img_paths = []\n","for path in path_sets:\n","    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n","        img_paths.append(img_path)"],"metadata":{"id":"dAsMqymxg26Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Utils\n","This section contains : \n","\n","1.   a method to load a model\n","2.   a method to get a estimation of the number of people and the density map based on an image\n","\n"],"metadata":{"id":"9Ql9BRHyktpF"}},{"cell_type":"code","source":["#return the loaded model located at model_path (or the basic shangai partAmodel if no path is given ) \n","#using gpu or using cpu (if the use_gpu parameter is set to False)\n","def load_model(model_path = '/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/model_best.pth.tar', use_gpu = False):\n","  from torchvision import datasets, transforms\n","  transform=transforms.Compose([\n","                        transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                      std=[0.229, 0.224, 0.225]),\n","                    ])\n","  model = CSRNet()\n","  if use_gpu:\n","    model = model.cuda()\n","  else:\n","    model = model.cpu()\n","  checkpoint = torch.load(model_path)\n","  model.load_state_dict(checkpoint['state_dict'])\n","  return model"],"metadata":{"id":"8Hp6AF_Kk86M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model()\n","\n","#To plot the image density map from the output, use : \n","#plt.imshow(np.squeeze(output.detach().cpu().numpy(),(0,1)),cmap=CM.jet)\n","def prediction(model,image_path, use_gpu = True):\n","  img = transform(Image.open(image_path).convert('RGB')).cuda()\n","  output = model(img.unsqueeze(0))\n","  people_nbr = int(output.detach().cpu().sum().numpy())\n","  return people_nbr, output\n"],"metadata":{"id":"BRAacRbdk9DF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645179693375,"user_tz":-60,"elapsed":392,"user":{"displayName":"Louis Robins","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhueyELRByt_6yHYZLZUBDypbjIY4OwCQ6n_lCg=s64","userId":"13275034401234860759"}},"outputId":"d7c6a877-46c3-4532-b8ef-d5bef7edc85a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dict'>\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"583KwIGPUPvi","executionInfo":{"status":"ok","timestamp":1645179195014,"user_tz":-60,"elapsed":407,"user":{"displayName":"Louis Robins","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhueyELRByt_6yHYZLZUBDypbjIY4OwCQ6n_lCg=s64","userId":"13275034401234860759"}},"outputId":"4d430438-57b9-4c21-a33c-6e69e066f359"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSRNet(\n","  (frontend): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","  )\n","  (backend): Sequential(\n","    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","    (3): ReLU(inplace=True)\n","    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","    (11): ReLU(inplace=True)\n","  )\n","  (output_layer): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",")\n"]}]},{"cell_type":"markdown","source":["#Evaluation and Visualization"],"metadata":{"id":"cVTiyh3hk9Tt"}},{"cell_type":"code","source":["#Load models\n","model1 = load_model('/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/PartAmodel_best.pth.tar') #model shangai part1\n","model2 = load_model(model_path ='/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/model_best.pth.tar') #model trained on barb94"],"metadata":{"id":"mjx656_slAi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calculate and print the MAE of the models\n","def MAE_eval(model):\n","  mae = 0\n","  for i in range(len(img_paths)):\n","      img = transform(Image.open(img_paths[i]).convert('RGB')).cuda()\n","      gt_file = h5py.File(img_paths[i].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n","      groundtruth = np.asarray(gt_file['density'])\n","      output = model(img.unsqueeze(0))\n","      mae += abs(output.detach().cpu().sum().numpy()-np.sum(groundtruth))\n","      \n","  return mae/len(img_paths)\n","\n","print(MAE_eval(model))\n","print(MAE_eval(model2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mW2lkDRAhoBk","executionInfo":{"status":"ok","timestamp":1644428110736,"user_tz":-60,"elapsed":60851,"user":{"displayName":"Louis Robins","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhueyELRByt_6yHYZLZUBDypbjIY4OwCQ6n_lCg=s64","userId":"13275034401234860759"}},"outputId":"ffda6625-cd55-40bc-bcf5-0c0c8a6ed77b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4.313128113746642\n","1.5741261596029452\n"]}]},{"cell_type":"code","source":["#print estimated number and real number and show's the images and density representations\n","indexes = [5,18,19,22,36]\n","plt.figure(figsize = (100,100))\n","for i in range(len(indexes)):\n","    gt_file = h5py.File(img_paths[indexes[i]].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n","    groundtruth = np.asarray(gt_file['density'])\n","    nbr1, output = prediction(model,img_paths[indexes[i]])\n","    nbr2, output2= prediction(model2,img_paths[indexes[i]])\n","    \n","    plt.subplot(5,4,i*4+1)\n","    plt.imshow(Image.open(img_paths[indexes[i]]))\n","    plt.title(\"Raw image\", fontsize=75)\n","\n","    plt.subplot(5,4,i*4+2)\n","    plt.imshow(groundtruth,cmap=CM.jet)\n","    plt.title(\"Groundtruth : \" + str(int(np.sum(groundtruth))), fontsize=75)\n","\n","    plt.subplot(5,4,i*4+3)\n","    plt.imshow(np.squeeze(output.detach().cpu().numpy(),(0,1)),cmap=CM.jet)\n","    plt.title(\"Model prediction : \" + str(nbr1), fontsize=75)\n","\n","    \n","    plt.subplot(5,4,i*4+4)\n","    plt.imshow(np.squeeze(output2.detach().cpu().numpy(),(0,1)),cmap=CM.jet)\n","    plt.title(\"Model prediction : \" + str(nbr2), fontsize=75)\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1toEQp7Pa8osbwcqk2WwphvLkuCyWy1xk"},"id":"7kjnmukMiIXa","executionInfo":{"status":"ok","timestamp":1644428049890,"user_tz":-60,"elapsed":26348,"user":{"displayName":"Louis Robins","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhueyELRByt_6yHYZLZUBDypbjIY4OwCQ6n_lCg=s64","userId":"13275034401234860759"}},"outputId":"7808ddb5-4ad7-4b13-be5d-1432ffd61d9b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}