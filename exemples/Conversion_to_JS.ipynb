{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCSFCpnXvx7P"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rng0aHCyv2IR"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhGqUOCLv38g",
        "outputId": "5e207922-bcd8-4831-811f-0a9121802930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch')\n",
        "\n",
        "import os\n",
        "from image import *\n",
        "from model import CSRNet\n",
        "import glob\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ynhsRrv9ap"
      },
      "source": [
        "##Variables\n",
        "Paramaters to change according to the wanted output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDWNfWZsw6wS"
      },
      "outputs": [],
      "source": [
        "#parameters to change\n",
        "INPUT_MODEL_NAME = 'A10_SH_C.tar' #Name of the saved CSRNet model weight\n",
        "OUTPUT_MODEL_NAME = 'A10_SH_512x384' # Will be directory with the json and the bins, usable with tensorflowJS\n",
        "Input_img_size = (512,384) #Size of the model predictions\n",
        "use_gpu = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDBj2WefxErH"
      },
      "source": [
        "#paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SL2m_SawKAo"
      },
      "outputs": [],
      "source": [
        "root = '/content/gdrive/MyDrive/TFE_crowd_counting'\n",
        "\n",
        "scripts_path = os.path.join(root,'CSRNet-pytorch')\n",
        "models_path = os.path.join(scripts_path,'models')\n",
        "onnx_path = os.path.join(scripts_path,'models/ONNX')\n",
        "input_model_path = os.path.join(models_path,INPUT_MODEL_NAME)\n",
        "onnx_model_path = os.path.join(onnx_path, OUTPUT_MODEL_NAME+'.onnx')\n",
        "tf_model_path = os.path.join(models_path, OUTPUT_MODEL_NAME+'.pb')\n",
        "output_path = os.path.join(models_path, OUTPUT_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "fNCvGnDeYpL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaJs12xVxmeJ"
      },
      "outputs": [],
      "source": [
        "#return the loaded model located at model_path (or the basic shangai partAmodel if no path is given ) \n",
        "#using gpu or using cpu (if the use_gpu parameter is set to False)\n",
        "def load_model(model_path, use_gpu = use_gpu):\n",
        "  from torchvision import datasets, transforms\n",
        "  transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225]),\n",
        "                    ])\n",
        "  model = CSRNet()\n",
        "  checkpoint = torch.load(model_path)\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  if use_gpu:\n",
        "    model = model.cuda()\n",
        "  else:\n",
        "    model = model.cpu()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nY3Xsb1yARQ"
      },
      "source": [
        "#Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIa0HscpyEBx",
        "outputId": "0b6b255f-88bf-4257-dd63-38f79866d4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:286: UserWarning: `add_node_names' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `add_node_names` argument will be ignored.\n",
            "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:286: UserWarning: `do_constant_folding' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `do_constant_folding` argument will be ignored.\n",
            "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n"
          ]
        }
      ],
      "source": [
        "#Step 1: convert to onnx\n",
        "use_gpu = False\n",
        "model = load_model(input_model_path)\n",
        "input_names = [ \"image\" ]\n",
        "output_names = [ \"output1\" ]\n",
        "if use_gpu:\n",
        "  dummy_input = torch.randn(1, 3, Input_img_size[0], Input_img_size[1], device='cuda')\n",
        "else:\n",
        "  dummy_input = torch.randn(1, 3, Input_img_size[1], Input_img_size[0])\n",
        "torch.onnx.export(model, dummy_input, onnx_model_path, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNRV1m30y6Q8",
        "outputId": "fdcd1425-8449-4121-8e1f-cdd7c1db0695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-20 12:21:03,532 - onnx-tf - INFO - Start converting onnx pb to tf saved model\n",
            "2022-05-20 12:21:04.337940: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:absl:Function `__call__` contains input name(s) input.1 with unsupported characters which will be renamed to input_1 in the SavedModel.\n",
            "2022-05-20 12:21:10.971681: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "2022-05-20 12:21:12,253 - onnx-tf - INFO - Converting completes successfully.\n",
            "INFO:onnx-tf:Converting completes successfully.\n"
          ]
        }
      ],
      "source": [
        "#Step 2: export to tensorflow\n",
        "#!pip install git+https://github.com/onnx/onnx-tensorflow.git #May be commented if the package is already installed\n",
        "!onnx-tf convert -i {onnx_model_path} -o {tf_model_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUuE6BC7zMKI"
      },
      "outputs": [],
      "source": [
        "#Step 3: export to tensorflow.js\n",
        "#!pip install tensorflowjs #May be commented if the package is already installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtOPKDwdVH3H",
        "outputId": "4725cf8a-3713-4760-d451-3a21af35ee3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/models/A10_SH_256x192.pb\n",
            "/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/models/A10_SH_256x192\n"
          ]
        }
      ],
      "source": [
        "#Copy past the two path as argument for conversion\n",
        "print(tf_model_path)\n",
        "print(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLt07r9oOxyI",
        "outputId": "ae35cc8d-e9de-4b3e-860c-cc86aa26ca02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-20 12:21:24.979366: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Writing weight file /content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/models/A10_SH_512x384/model.json...\n"
          ]
        }
      ],
      "source": [
        "!tensorflowjs_converter --input_format='tf_saved_model' '/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/models/A10_SH_512x384.pb' '/content/gdrive/MyDrive/TFE_crowd_counting/CSRNet-pytorch/models/A10_SH_512x384'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Conversion_to_JS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}